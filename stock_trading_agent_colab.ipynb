{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juMWKT0d1VJ2"
      },
      "source": [
        "# Stock-trading RL Agent (Adilbai) + NSE integration\n",
        "Run cells step‑by‑step."
      ],
      "id": "juMWKT0d1VJ2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm_9NU7H1VJ4",
        "outputId": "d9ac0381-d062-4d04-f5ca-785fb4f85c90"
      },
      "source": [
        "!git clone https://huggingface.co/Adilbai/stock-trading-rl-agent.git repo || true\n",
        "!pip install -q stable-baselines3 huggingface_hub gym pandas numpy matplotlib ta nsepython nsetools"
      ],
      "id": "Dm_9NU7H1VJ4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'repo'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (74/74), done.\u001b[K\n",
            "remote: Compressing objects: 100% (73/73), done.\u001b[K\n",
            "remote: Total 80 (delta 24), reused 0 (delta 0), pack-reused 6 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (80/80), 42.96 KiB | 1.65 MiB/s, done.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bcbba52",
        "outputId": "752e0191-afa8-45e1-9875-419c49194c1a"
      },
      "source": [
        "with open('dataprocessor.py', 'r') as f:\n",
        "    print(f.read())"
      ],
      "id": "8bcbba52",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import yfinance as yf\n",
            "import pandas as pd\n",
            "import numpy as np\n",
            "from typing import List, Dict, Optional, Tuple\n",
            "import os\n",
            "import logging\n",
            "from datetime import datetime, timedelta\n",
            "import pickle\n",
            "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
            "import time\n",
            "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
            "import warnings\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "# Set up logging\n",
            "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
            "logger = logging.getLogger(__name__)\n",
            "\n",
            "class StockDataProcessor:\n",
            "    \"\"\"\n",
            "    A comprehensive class for downloading, processing, and preprocessing stock data\n",
            "    from Yahoo Finance for reinforcement learning applications.\n",
            "    \"\"\"\n",
            "    \n",
            "    def __init__(self, data_dir: str = \"stock_data\", cache_dir: str = \"cache\"):\n",
            "        self.data_dir = data_dir\n",
            "        self.cache_dir = cache_dir\n",
            "        self.scalers = {}\n",
            "        \n",
            "        # Create directories if they don't exist\n",
            "        os.makedirs(data_dir, exist_ok=True)\n",
            "        os.makedirs(cache_dir, exist_ok=True)\n",
            "        \n",
            "    def get_sp500_tickers(self) -> List[str]:\n",
            "        \"\"\"Get S&P 500 stock tickers\"\"\"\n",
            "        try:\n",
            "            # Download S&P 500 list from Wikipedia\n",
            "            url = 'https://en.wikipedia.org/wiki/List_of_S%26P_500_companies'\n",
            "            tables = pd.read_html(url)\n",
            "            sp500_table = tables[0]\n",
            "            tickers = sp500_table['Symbol'].tolist()\n",
            "            # Clean tickers (remove dots, etc.)\n",
            "            tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
            "            logger.info(f\"Retrieved {len(tickers)} S&P 500 tickers\")\n",
            "            return tickers\n",
            "        except Exception as e:\n",
            "            logger.error(f\"Error fetching S&P 500 tickers: {e}\")\n",
            "            # Fallback to a smaller list of popular stocks\n",
            "            return ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'JNJ', 'V']\n",
            "    \n",
            "    def download_stock_data(self, \n",
            "                          ticker: str, \n",
            "                          period: str = \"10y\", \n",
            "                          interval: str = \"1d\") -> Optional[pd.DataFrame]:\n",
            "        \"\"\"\n",
            "        Download stock data for a single ticker\n",
            "        \n",
            "        Args:\n",
            "            ticker: Stock symbol\n",
            "            period: Time period (1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, 10y, ytd, max)\n",
            "            interval: Data interval (1m, 2m, 5m, 15m, 30m, 60m, 90m, 1h, 1d, 5d, 1wk, 1mo, 3mo)\n",
            "        \"\"\"\n",
            "        try:\n",
            "            stock = yf.Ticker(ticker)\n",
            "            data = stock.history(period=period, interval=interval)\n",
            "            \n",
            "            if data.empty:\n",
            "                logger.warning(f\"No data found for {ticker}\")\n",
            "                return None\n",
            "                \n",
            "            # Add ticker column\n",
            "            data['Ticker'] = ticker\n",
            "            data.reset_index(inplace=True)\n",
            "            \n",
            "            logger.info(f\"Downloaded {len(data)} records for {ticker}\")\n",
            "            return data\n",
            "            \n",
            "        except Exception as e:\n",
            "            logger.error(f\"Error downloading data for {ticker}: {e}\")\n",
            "            return None\n",
            "    \n",
            "    def download_multiple_stocks(self, \n",
            "                                tickers: List[str], \n",
            "                                period: str = \"10y\",\n",
            "                                interval: str = \"1d\",\n",
            "                                max_workers: int = 10) -> pd.DataFrame:\n",
            "        \"\"\"\n",
            "        Download stock data for multiple tickers using parallel processing\n",
            "        \"\"\"\n",
            "        all_data = []\n",
            "        \n",
            "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
            "            # Submit all download tasks\n",
            "            future_to_ticker = {\n",
            "                executor.submit(self.download_stock_data, ticker, period, interval): ticker \n",
            "                for ticker in tickers\n",
            "            }\n",
            "            \n",
            "            # Collect results\n",
            "            for future in as_completed(future_to_ticker):\n",
            "                ticker = future_to_ticker[future]\n",
            "                try:\n",
            "                    data = future.result()\n",
            "                    if data is not None:\n",
            "                        all_data.append(data)\n",
            "                except Exception as e:\n",
            "                    logger.error(f\"Error processing {ticker}: {e}\")\n",
            "                \n",
            "                # Rate limiting\n",
            "                time.sleep(0.1)\n",
            "        \n",
            "        if all_data:\n",
            "            combined_data = pd.concat(all_data, ignore_index=True)\n",
            "            logger.info(f\"Combined data shape: {combined_data.shape}\")\n",
            "            return combined_data\n",
            "        else:\n",
            "            return pd.DataFrame()\n",
            "    \n",
            "    def calculate_technical_indicators(self, df: pd.DataFrame) -> pd.DataFrame:\n",
            "        \"\"\"\n",
            "        Calculate technical indicators for each stock\n",
            "        \"\"\"\n",
            "        logger.info(\"Calculating technical indicators...\")\n",
            "        \n",
            "        result_dfs = []\n",
            "        \n",
            "        for ticker in df['Ticker'].unique():\n",
            "            ticker_data = df[df['Ticker'] == ticker].copy()\n",
            "            ticker_data = ticker_data.sort_values('Date')\n",
            "            \n",
            "            # Moving averages\n",
            "            ticker_data['SMA_5'] = ticker_data['Close'].rolling(window=5).mean()\n",
            "            ticker_data['SMA_10'] = ticker_data['Close'].rolling(window=10).mean()\n",
            "            ticker_data['SMA_20'] = ticker_data['Close'].rolling(window=20).mean()\n",
            "            ticker_data['SMA_50'] = ticker_data['Close'].rolling(window=50).mean()\n",
            "            \n",
            "            # Exponential moving averages\n",
            "            ticker_data['EMA_12'] = ticker_data['Close'].ewm(span=12).mean()\n",
            "            ticker_data['EMA_26'] = ticker_data['Close'].ewm(span=26).mean()\n",
            "            \n",
            "            # MACD\n",
            "            ticker_data['MACD'] = ticker_data['EMA_12'] - ticker_data['EMA_26']\n",
            "            ticker_data['MACD_Signal'] = ticker_data['MACD'].ewm(span=9).mean()\n",
            "            ticker_data['MACD_Histogram'] = ticker_data['MACD'] - ticker_data['MACD_Signal']\n",
            "            \n",
            "            # RSI\n",
            "            delta = ticker_data['Close'].diff()\n",
            "            gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
            "            loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
            "            rs = gain / loss\n",
            "            ticker_data['RSI'] = 100 - (100 / (1 + rs))\n",
            "            \n",
            "            # Bollinger Bands\n",
            "            ticker_data['BB_Middle'] = ticker_data['Close'].rolling(window=20).mean()\n",
            "            bb_std = ticker_data['Close'].rolling(window=20).std()\n",
            "            ticker_data['BB_Upper'] = ticker_data['BB_Middle'] + (bb_std * 2)\n",
            "            ticker_data['BB_Lower'] = ticker_data['BB_Middle'] - (bb_std * 2)\n",
            "            ticker_data['BB_Width'] = ticker_data['BB_Upper'] - ticker_data['BB_Lower']\n",
            "            ticker_data['BB_Position'] = (ticker_data['Close'] - ticker_data['BB_Lower']) / ticker_data['BB_Width']\n",
            "            \n",
            "            # Volatility\n",
            "            ticker_data['Volatility'] = ticker_data['Close'].rolling(window=20).std()\n",
            "            \n",
            "            # Price change features\n",
            "            ticker_data['Price_Change'] = ticker_data['Close'].pct_change()\n",
            "            ticker_data['Price_Change_5d'] = ticker_data['Close'].pct_change(periods=5)\n",
            "            ticker_data['High_Low_Ratio'] = ticker_data['High'] / ticker_data['Low']\n",
            "            ticker_data['Open_Close_Ratio'] = ticker_data['Open'] / ticker_data['Close']\n",
            "            \n",
            "            # Volume features\n",
            "            ticker_data['Volume_SMA'] = ticker_data['Volume'].rolling(window=20).mean()\n",
            "            ticker_data['Volume_Ratio'] = ticker_data['Volume'] / ticker_data['Volume_SMA']\n",
            "            \n",
            "            result_dfs.append(ticker_data)\n",
            "        \n",
            "        result = pd.concat(result_dfs, ignore_index=True)\n",
            "        logger.info(f\"Technical indicators calculated. New shape: {result.shape}\")\n",
            "        return result\n",
            "    \n",
            "    def create_lagged_features(self, df: pd.DataFrame, lags: List[int] = [1, 2, 3, 5, 10]) -> pd.DataFrame:\n",
            "        \"\"\"\n",
            "        Create lagged features for time series analysis\n",
            "        \"\"\"\n",
            "        logger.info(\"Creating lagged features...\")\n",
            "        \n",
            "        result_dfs = []\n",
            "        feature_columns = ['Close', 'Volume', 'Price_Change', 'RSI', 'MACD', 'Volatility']\n",
            "        \n",
            "        for ticker in df['Ticker'].unique():\n",
            "            ticker_data = df[df['Ticker'] == ticker].copy()\n",
            "            ticker_data = ticker_data.sort_values('Date')\n",
            "            \n",
            "            for col in feature_columns:\n",
            "                if col in ticker_data.columns:\n",
            "                    for lag in lags:\n",
            "                        ticker_data[f'{col}_lag_{lag}'] = ticker_data[col].shift(lag)\n",
            "            \n",
            "            result_dfs.append(ticker_data)\n",
            "        \n",
            "        result = pd.concat(result_dfs, ignore_index=True)\n",
            "        logger.info(f\"Lagged features created. New shape: {result.shape}\")\n",
            "        return result\n",
            "    \n",
            "    def create_future_returns(self, df: pd.DataFrame, horizons: List[int] = [1, 5, 10, 20]) -> pd.DataFrame:\n",
            "        \"\"\"\n",
            "        Create future return targets for prediction\n",
            "        \"\"\"\n",
            "        logger.info(\"Creating future return targets...\")\n",
            "        \n",
            "        result_dfs = []\n",
            "        \n",
            "        for ticker in df['Ticker'].unique():\n",
            "            ticker_data = df[df['Ticker'] == ticker].copy()\n",
            "            ticker_data = ticker_data.sort_values('Date')\n",
            "            \n",
            "            for horizon in horizons:\n",
            "                ticker_data[f'Future_Return_{horizon}d'] = ticker_data['Close'].shift(-horizon) / ticker_data['Close'] - 1\n",
            "                \n",
            "                # Create binary classification targets\n",
            "                ticker_data[f'Future_Up_{horizon}d'] = (ticker_data[f'Future_Return_{horizon}d'] > 0).astype(int)\n",
            "                \n",
            "                # Create categorical targets (strong down, down, up, strong up)\n",
            "                returns = ticker_data[f'Future_Return_{horizon}d']\n",
            "                ticker_data[f'Future_Category_{horizon}d'] = pd.cut(\n",
            "                    returns, \n",
            "                    bins=[-np.inf, -0.02, 0, 0.02, np.inf], \n",
            "                    labels=[0, 1, 2, 3]\n",
            "                ).astype(float)\n",
            "            \n",
            "            result_dfs.append(ticker_data)\n",
            "        \n",
            "        result = pd.concat(result_dfs, ignore_index=True)\n",
            "        logger.info(f\"Future return targets created. New shape: {result.shape}\")\n",
            "        return result\n",
            "    \n",
            "    def clean_and_normalize_data(self, df: pd.DataFrame) -> pd.DataFrame:\n",
            "        \"\"\"\n",
            "        Clean and normalize the data for ML/RL\n",
            "        \"\"\"\n",
            "        logger.info(\"Cleaning and normalizing data...\")\n",
            "        \n",
            "        # Remove rows with too many NaN values\n",
            "        df = df.dropna(thresh=len(df.columns) * 0.7)\n",
            "        \n",
            "        # Forward fill remaining NaN values\n",
            "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
            "        df[numeric_columns] = df[numeric_columns].fillna(method='ffill')\n",
            "        \n",
            "        # Remove infinite values\n",
            "        df = df.replace([np.inf, -np.inf], np.nan)\n",
            "        df = df.dropna()\n",
            "        \n",
            "        logger.info(f\"Data cleaned. Final shape: {df.shape}\")\n",
            "        return df\n",
            "    \n",
            "    def create_rl_states_actions(self, df: pd.DataFrame) -> Dict:\n",
            "        \"\"\"\n",
            "        Create state and action spaces suitable for reinforcement learning\n",
            "        \"\"\"\n",
            "        logger.info(\"Creating RL state and action representations...\")\n",
            "        \n",
            "        # Define state features (technical indicators and market data)\n",
            "        state_features = [\n",
            "            'Open', 'High', 'Low', 'Close', 'Volume',\n",
            "            'SMA_5', 'SMA_10', 'SMA_20', 'SMA_50',\n",
            "            'EMA_12', 'EMA_26', 'MACD', 'MACD_Signal', 'RSI',\n",
            "            'BB_Position', 'BB_Width', 'Volatility',\n",
            "            'Price_Change', 'High_Low_Ratio', 'Volume_Ratio'\n",
            "        ]\n",
            "        \n",
            "        # Add lagged features to state\n",
            "        lag_features = [col for col in df.columns if '_lag_' in col]\n",
            "        state_features.extend(lag_features)\n",
            "        \n",
            "        # Filter existing features\n",
            "        state_features = [feat for feat in state_features if feat in df.columns]\n",
            "        \n",
            "        # Normalize state features\n",
            "        scaler = StandardScaler()\n",
            "        df_scaled = df.copy()\n",
            "        df_scaled[state_features] = scaler.fit_transform(df[state_features])\n",
            "        \n",
            "        # Define action space (0: Hold, 1: Buy, 2: Sell)\n",
            "        # You can expand this based on your RL strategy\n",
            "        \n",
            "        # Create sequences for each stock\n",
            "        rl_data = {}\n",
            "        sequence_length = 60  # Number of days to look back\n",
            "        \n",
            "        for ticker in df_scaled['Ticker'].unique():\n",
            "            ticker_data = df_scaled[df_scaled['Ticker'] == ticker].sort_values('Date')\n",
            "            \n",
            "            states = []\n",
            "            rewards = []\n",
            "            dates = []\n",
            "            \n",
            "            for i in range(sequence_length, len(ticker_data)):\n",
            "                # State: sequence of technical indicators\n",
            "                state_sequence = ticker_data.iloc[i-sequence_length:i][state_features].values\n",
            "                states.append(state_sequence)\n",
            "                \n",
            "                # Reward: next day return (can be modified based on your RL objective)\n",
            "                if 'Future_Return_1d' in ticker_data.columns:\n",
            "                    reward = ticker_data.iloc[i]['Future_Return_1d']\n",
            "                else:\n",
            "                    current_price = ticker_data.iloc[i]['Close']\n",
            "                    if i < len(ticker_data) - 1:\n",
            "                        next_price = ticker_data.iloc[i+1]['Close']\n",
            "                        reward = (next_price - current_price) / current_price\n",
            "                    else:\n",
            "                        reward = 0\n",
            "                \n",
            "                rewards.append(reward)\n",
            "                dates.append(ticker_data.iloc[i]['Date'])\n",
            "            \n",
            "            rl_data[ticker] = {\n",
            "                'states': np.array(states),\n",
            "                'rewards': np.array(rewards),\n",
            "                'dates': dates,\n",
            "                'state_features': state_features\n",
            "            }\n",
            "        \n",
            "        logger.info(f\"RL data created for {len(rl_data)} stocks\")\n",
            "        return rl_data, scaler\n",
            "    \n",
            "    def save_processed_data(self, data: pd.DataFrame, rl_data: Dict, scaler, filename_prefix: str = \"processed_stock_data\"):\n",
            "        \"\"\"\n",
            "        Save processed data to files\n",
            "        \"\"\"\n",
            "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
            "        \n",
            "        # Save CSV data\n",
            "        csv_filename = f\"{self.data_dir}/{filename_prefix}_{timestamp}.csv\"\n",
            "        data.to_csv(csv_filename, index=False)\n",
            "        logger.info(f\"CSV data saved to {csv_filename}\")\n",
            "        \n",
            "        # Save RL data\n",
            "        rl_filename = f\"{self.data_dir}/{filename_prefix}_rl_{timestamp}.pkl\"\n",
            "        with open(rl_filename, 'wb') as f:\n",
            "            pickle.dump(rl_data, f)\n",
            "        logger.info(f\"RL data saved to {rl_filename}\")\n",
            "        \n",
            "        # Save scaler\n",
            "        scaler_filename = f\"{self.data_dir}/{filename_prefix}_scaler_{timestamp}.pkl\"\n",
            "        with open(scaler_filename, 'wb') as f:\n",
            "            pickle.dump(scaler, f)\n",
            "        logger.info(f\"Scaler saved to {scaler_filename}\")\n",
            "        \n",
            "        return csv_filename, rl_filename, scaler_filename\n",
            "    \n",
            "    def process_stocks_pipeline(self, \n",
            "                               tickers: Optional[List[str]] = None,\n",
            "                               period: str = \"10y\",\n",
            "                               interval: str = \"1d\",\n",
            "                               use_sp500: bool = True) -> Tuple[pd.DataFrame, Dict, object]:\n",
            "        \"\"\"\n",
            "        Complete pipeline for processing stock data\n",
            "        \"\"\"\n",
            "        logger.info(\"Starting stock data processing pipeline...\")\n",
            "        \n",
            "        # Get tickers\n",
            "        if tickers is None:\n",
            "            if use_sp500:\n",
            "                tickers = self.get_sp500_tickers()\n",
            "            else:\n",
            "                tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']  # Default list\n",
            "        \n",
            "        # Download data\n",
            "        logger.info(f\"Downloading data for {len(tickers)} tickers...\")\n",
            "        raw_data = self.download_multiple_stocks(tickers, period, interval)\n",
            "        \n",
            "        if raw_data.empty:\n",
            "            logger.error(\"No data downloaded. Exiting.\")\n",
            "            return None, None, None\n",
            "        \n",
            "        # Process data\n",
            "        data_with_indicators = self.calculate_technical_indicators(raw_data)\n",
            "        data_with_lags = self.create_lagged_features(data_with_indicators)\n",
            "        data_with_targets = self.create_future_returns(data_with_lags)\n",
            "        cleaned_data = self.clean_and_normalize_data(data_with_targets)\n",
            "        \n",
            "        # Create RL data\n",
            "        rl_data, scaler = self.create_rl_states_actions(cleaned_data)\n",
            "        \n",
            "        # Save data\n",
            "        self.save_processed_data(cleaned_data, rl_data, scaler)\n",
            "        \n",
            "        logger.info(\"Pipeline completed successfully!\")\n",
            "        return cleaned_data, rl_data, scaler\n",
            "\n",
            "# Example usage and utility functions\n",
            "def example_usage():\n",
            "    \"\"\"\n",
            "    Example of how to use the StockDataProcessor\n",
            "    \"\"\"\n",
            "    # Initialize processor\n",
            "    processor = StockDataProcessor()\n",
            "    \n",
            "    # Option 1: Process S&P 500 stocks\n",
            "    print(\"Processing S&P 500 stocks...\")\n",
            "    data, rl_data, scaler = processor.process_stocks_pipeline(use_sp500=True, period=\"5y\")\n",
            "    \n",
            "    # Option 2: Process specific stocks\n",
            "    # custom_tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA']\n",
            "    # data, rl_data, scaler = processor.process_stocks_pipeline(tickers=custom_tickers, period=\"10y\")\n",
            "    \n",
            "    if data is not None:\n",
            "        print(f\"Processed data shape: {data.shape}\")\n",
            "        print(f\"Features: {data.columns.tolist()}\")\n",
            "        print(f\"RL data available for {len(rl_data)} stocks\")\n",
            "        \n",
            "        # Example: Access RL data for a specific stock\n",
            "        if 'AAPL' in rl_data:\n",
            "            aapl_states = rl_data['AAPL']['states']\n",
            "            aapl_rewards = rl_data['AAPL']['rewards']\n",
            "            print(f\"AAPL: {aapl_states.shape[0]} sequences, each with {aapl_states.shape[1]} timesteps and {aapl_states.shape[2]} features\")\n",
            "\n",
            "def load_processed_data(rl_filename: str, scaler_filename: str) -> Tuple[Dict, object]:\n",
            "    \"\"\"\n",
            "    Load previously processed RL data\n",
            "    \"\"\"\n",
            "    with open(rl_filename, 'rb') as f:\n",
            "        rl_data = pickle.load(f)\n",
            "    \n",
            "    with open(scaler_filename, 'rb') as f:\n",
            "        scaler = pickle.load(f)\n",
            "    \n",
            "    return rl_data, scaler\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    example_usage()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "271b759c",
        "outputId": "08e6e1fc-fd0f-4bbd-d3ab-9ffa1ae6c0d1"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import yfinance as yf\n",
        "\n",
        "ticker = \"RELIANCE.NS\" # Using the yfinance symbol for Reliance (NSE)\n",
        "\n",
        "# Calculate start and end dates for a longer period, e.g., 2 years\n",
        "end_date = datetime.now()\n",
        "start_date = end_date - timedelta(days=2*365) # Fetch data for the last 2 years\n",
        "\n",
        "# Fetch historical data from Yahoo Finance for the NSE-listed stock\n",
        "data = yf.download(ticker, start=start_date.strftime('%Y-%m-%d'), end=end_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "# Display the head of the DataFrame\n",
        "display(data.head())"
      ],
      "id": "271b759c",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Price             Close         High          Low         Open      Volume\n",
              "Ticker      RELIANCE.NS  RELIANCE.NS  RELIANCE.NS  RELIANCE.NS RELIANCE.NS\n",
              "Date                                                                      \n",
              "2023-11-13  1148.797241  1153.760506  1147.357822  1152.916654     3854810\n",
              "2023-11-15  1169.568481  1172.298277  1154.951691  1161.403935    12220648\n",
              "2023-11-16  1171.677856  1178.353423  1164.853368  1166.913195    13134910\n",
              "2023-11-17  1169.121826  1177.906780  1167.384684  1167.806488     7758634\n",
              "2023-11-20  1166.044678  1170.536335  1159.617153  1165.647592     4490186"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-992d3dae-4de1-4448-aa8e-62c03ab129a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th>Price</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Ticker</th>\n",
              "      <th>RELIANCE.NS</th>\n",
              "      <th>RELIANCE.NS</th>\n",
              "      <th>RELIANCE.NS</th>\n",
              "      <th>RELIANCE.NS</th>\n",
              "      <th>RELIANCE.NS</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-11-13</th>\n",
              "      <td>1148.797241</td>\n",
              "      <td>1153.760506</td>\n",
              "      <td>1147.357822</td>\n",
              "      <td>1152.916654</td>\n",
              "      <td>3854810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-15</th>\n",
              "      <td>1169.568481</td>\n",
              "      <td>1172.298277</td>\n",
              "      <td>1154.951691</td>\n",
              "      <td>1161.403935</td>\n",
              "      <td>12220648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-16</th>\n",
              "      <td>1171.677856</td>\n",
              "      <td>1178.353423</td>\n",
              "      <td>1164.853368</td>\n",
              "      <td>1166.913195</td>\n",
              "      <td>13134910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-17</th>\n",
              "      <td>1169.121826</td>\n",
              "      <td>1177.906780</td>\n",
              "      <td>1167.384684</td>\n",
              "      <td>1167.806488</td>\n",
              "      <td>7758634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-11-20</th>\n",
              "      <td>1166.044678</td>\n",
              "      <td>1170.536335</td>\n",
              "      <td>1159.617153</td>\n",
              "      <td>1165.647592</td>\n",
              "      <td>4490186</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-992d3dae-4de1-4448-aa8e-62c03ab129a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-992d3dae-4de1-4448-aa8e-62c03ab129a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-992d3dae-4de1-4448-aa8e-62c03ab129a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-db1f4217-86e6-4de7-9ae7-168149af0d85\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-db1f4217-86e6-4de7-9ae7-168149af0d85')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-db1f4217-86e6-4de7-9ae7-168149af0d85 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": [\n        \"Date\",\n        \"\"\n      ],\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2023-11-13 00:00:00\",\n        \"max\": \"2023-11-20 00:00:00\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2023-11-15 00:00:00\",\n          \"2023-11-20 00:00:00\",\n          \"2023-11-16 00:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Close\",\n        \"RELIANCE.NS\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.301426737102307,\n        \"min\": 1148.7972412109375,\n        \"max\": 1171.6778564453125,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1169.5684814453125,\n          1166.044677734375,\n          1171.6778564453125\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"High\",\n        \"RELIANCE.NS\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9.9994648623689,\n        \"min\": 1153.7605056745233,\n        \"max\": 1178.3534231349859,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1172.2982770196893,\n          1170.5363354915235,\n          1178.3534231349859\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Low\",\n        \"RELIANCE.NS\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8.011480596848637,\n        \"min\": 1147.3578218124285,\n        \"max\": 1167.3846835483773,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1154.9516911953863,\n          1159.617152805321,\n          1164.8533675821152\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Open\",\n        \"RELIANCE.NS\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.116105360160936,\n        \"min\": 1152.9166537769547,\n        \"max\": 1167.8064883385834,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          1161.4039352802765,\n          1165.647592311094,\n          1166.9131951067154\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": [\n        \"Volume\",\n        \"RELIANCE.NS\"\n      ],\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4281208,\n        \"min\": 3854810,\n        \"max\": 13134910,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          12220648,\n          4490186,\n          13134910\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8756e504",
        "outputId": "6d333a6a-7cc0-405a-8108-e5da6f245821"
      },
      "source": [
        "from dataprocessor import StockDataProcessor\n",
        "import pandas as pd # Ensure pandas is imported for MultiIndex handling\n",
        "\n",
        "# Ensure 'Date' is a column and add 'Ticker' column for the processor\n",
        "data_processed = data.reset_index()\n",
        "data_processed['Date'] = pd.to_datetime(data_processed['Date'])\n",
        "data_processed['Ticker'] = ticker\n",
        "\n",
        "# Flatten MultiIndex columns if they exist\n",
        "if isinstance(data_processed.columns, pd.MultiIndex):\n",
        "    # This assumes the relevant column names ('Close', 'Open', etc.) are in the first level\n",
        "    # and the ticker name is in the second level (e.g., ('Close', 'RELIANCE.NS'))\n",
        "    data_processed.columns = [col[0] if isinstance(col, tuple) else col for col in data_processed.columns]\n",
        "\n",
        "# After flattening, the column from reset_index() might be named 'index', so rename it to 'Date'\n",
        "data_processed = data_processed.rename(columns={'index': 'Date'})\n",
        "\n",
        "# Initialize the StockDataProcessor\n",
        "processor = StockDataProcessor()\n",
        "\n",
        "# Apply the processing pipeline steps manually\n",
        "print(\"Calculating technical indicators...\")\n",
        "data_with_indicators = processor.calculate_technical_indicators(data_processed)\n",
        "\n",
        "print(\"Creating lagged features...\")\n",
        "data_with_lags = processor.create_lagged_features(data_with_indicators)\n",
        "\n",
        "print(\"Creating future returns...\")\n",
        "data_with_targets = processor.create_future_returns(data_with_lags)\n",
        "\n",
        "print(\"Cleaning and normalizing data...\")\n",
        "cleaned_data = processor.clean_and_normalize_data(data_with_targets)\n",
        "\n",
        "print(\"Creating RL states and actions...\")\n",
        "rl_data, data_scaler = processor.create_rl_states_actions(cleaned_data)\n",
        "\n",
        "print(\"Data preparation for RL observation complete.\")\n",
        "\n",
        "# The 'rl_data' dictionary now contains the states for each ticker.\n",
        "# For 'RELIANCE.NS', the states would be in rl_data['RELIANCE.NS']['states']\n",
        "print(f\"RL data prepared for {len(rl_data)} stock(s).\")\n",
        "if ticker in rl_data:\n",
        "    reliance_states = rl_data[ticker]['states']\n",
        "    print(f\"{ticker} states shape: {reliance_states.shape}\")\n",
        "    print(f\"Example of a single observation (last state in sequence):\")\n",
        "    # Display the last observation as an example\n",
        "    if reliance_states.shape[0] > 0:\n",
        "        print(reliance_states[-1])\n",
        "    else:\n",
        "        print(\"No states generated for this ticker, possibly due to insufficient data after processing.\")\n",
        "\n",
        "# The 'data_scaler' is the scaler used for normalization, similar to the loaded 'scaler' from the model files.\n"
      ],
      "id": "8756e504",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating technical indicators...\n",
            "Creating lagged features...\n",
            "Creating future returns...\n",
            "Cleaning and normalizing data...\n",
            "Creating RL states and actions...\n",
            "Data preparation for RL observation complete.\n",
            "RL data prepared for 1 stock(s).\n",
            "RELIANCE.NS states shape: (384, 60, 50)\n",
            "Example of a single observation (last state in sequence):\n",
            "[[-0.07972499 -0.16294573 -0.06449771 ...  0.53152966  0.89285697\n",
            "   1.56205419]\n",
            " [-0.13241723 -0.21953975 -0.08411825 ...  0.36965828  0.6276044\n",
            "   1.65196096]\n",
            " [-0.00319202 -0.07509123 -0.01361813 ...  0.14745096  0.53699577\n",
            "   1.6200796 ]\n",
            " ...\n",
            " [ 0.95328169  1.01030108  0.9999447  ...  1.42568066  1.39687368\n",
            "   0.12852526]\n",
            " [ 1.06113912  0.97774997  0.99688024 ...  1.36577368  1.4576751\n",
            "   0.32477037]\n",
            " [ 0.8912129   1.0041979   0.99279304 ...  1.31262366  1.43400306\n",
            "   0.68564697]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d754d244"
      },
      "source": [
        "# Get the last observation from the processed data\n",
        "# The model expects a single observation of shape (1, sequence_length, n_features)\n",
        "current_observation = reliance_states[-1]\n",
        "\n",
        "# Reshape for prediction: add a batch dimension\n",
        "obs_for_prediction = np.expand_dims(current_observation, axis=0)\n",
        "\n",
        "print(f\"Shape of observation for prediction: {obs_for_prediction.shape}\")\n",
        "\n",
        "# Get trading decision from the model\n",
        "action, _states = model.predict(obs_for_prediction, deterministic=True)\n",
        "\n",
        "# Interpret action\n",
        "action_type = [\"HOLD\", \"BUY\", \"SELL\"][int(action[0])]\n",
        "position_size = action[1]     # 0-1: Fraction of available capital\n",
        "\n",
        "print(f\"\\nModel's Suggested Action: {action_type}, Position Size: {position_size:.2%}\")\n"
      ],
      "id": "d754d244",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdf57d04"
      },
      "source": [
        "Now that we have the raw historical data, the next step is to process it into the correct observation format that the model expects. The `README.md` mentions a `prepare_observation` function and suggests using `dataprocessor.py` for data preparation. We will need to investigate `dataprocessor.py` to understand how to create this function."
      ],
      "id": "bdf57d04"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8401400a",
        "outputId": "a86952e9-bd10-4f22-d4f6-f79ed2fe264c"
      },
      "source": [
        "from stable_baselines3 import PPO\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = PPO.load(\"final_model\")\n",
        "\n",
        "# Load the data scaler\n",
        "with open(\"scaler.pkl\", \"rb\") as f:\n",
        "    scaler = pickle.load(f)\n",
        "\n",
        "print(\"Model and scaler loaded successfully!\")"
      ],
      "id": "8401400a",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/save_util.py:165: DeprecationWarning: numpy.core.numeric is deprecated and has been renamed to numpy._core.numeric. The numpy._core namespace contains private NumPy internals and its use is discouraged, as NumPy internals can change without warning in any release. In practice, most real-world usage of numpy.core is to access functionality in the public NumPy API. If that is the case, use the public NumPy API. If not, you are using NumPy internals. If you would still like to access an internal attribute, use numpy._core.numeric._frombuffer.\n",
            "  deserialized_object = cloudpickle.loads(base64_object)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model and scaler loaded successfully!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/base.py:380: InconsistentVersionWarning: Trying to unpickle estimator StandardScaler from version 1.2.2 when using version 1.6.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "512c1d09",
        "outputId": "464629de-bbfd-42c9-9b98-37270d00510b"
      },
      "source": [
        "with open('README.md', 'r') as f:\n",
        "    print(f.read())"
      ],
      "id": "512c1d09",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "library_name: stable-baselines3\n",
            "tags:\n",
            "- reinforcement-learning\n",
            "- trading\n",
            "- finance\n",
            "- stock-market\n",
            "- ppo\n",
            "- quantitative-finance\n",
            "- algorithmic-trading\n",
            "- deep-reinforcement-learning\n",
            "- portfolio-management\n",
            "- financial-ai\n",
            "license: mit\n",
            "base_model: PPO\n",
            "model-index:\n",
            "- name: Stock Trading RL Agent\n",
            "  results:\n",
            "  - task:\n",
            "      type: reinforcement-learning\n",
            "      name: Stock Trading\n",
            "    dataset:\n",
            "      name: FAANG Stocks (5Y Historical Data)\n",
            "      type: financial-time-series\n",
            "    metrics:\n",
            "    - type: total_return\n",
            "      value: 162.87\n",
            "      name: Best Total Return (AMZN)\n",
            "    - type: sharpe_ratio\n",
            "      value: 0.74\n",
            "      name: Best Sharpe Ratio (AMZN)\n",
            "    - type: max_drawdown\n",
            "      value: 145.29\n",
            "      name: Best Max Drawdown (TSLA)\n",
            "    - type: win_rate\n",
            "      value: 52.11\n",
            "      name: Best Win Rate (MSFT)\n",
            "datasets:\n",
            "- yahoo-finance\n",
            "pipeline_tag: reinforcement-learning\n",
            "widget:\n",
            "- text: \"Technical Analysis Trading Agent\"\n",
            "  example_title: \"Stock Trading Decision\"\n",
            "---\n",
            "\n",
            "# 🚀 Stock Trading RL Agent - Advanced PPO Implementation\n",
            "\n",
            "<div align=\"center\">\n",
            "\n",
            "![Python](https://img.shields.io/badge/python-3.8+-blue.svg)\n",
            "![Stable-Baselines3](https://img.shields.io/badge/stable--baselines3-2.0+-green.svg)\n",
            "![License](https://img.shields.io/badge/license-MIT-blue.svg)\n",
            "![Status](https://img.shields.io/badge/status-production--ready-brightgreen.svg)\n",
            "\n",
            "**A state-of-the-art reinforcement learning agent for algorithmic stock trading using Proximal Policy Optimization (PPO)**\n",
            "\n",
            "[🔥 **Quick Start**](#quick-start) • [📊 **Performance**](#performance-metrics) • [💡 **Usage**](#usage) • [🛠️ **Technical Details**](#technical-details)\n",
            "\n",
            "</div>\n",
            "\n",
            "## 📈 Model Overview\n",
            "\n",
            "This model represents a sophisticated **reinforcement learning trading agent** trained using the **Proximal Policy Optimization (PPO)** algorithm. The agent learns to make optimal trading decisions across multiple stocks by analyzing technical indicators, market patterns, and portfolio states.\n",
            "\n",
            "### 🎯 Key Highlights\n",
            "\n",
            "- **🧠 Algorithm**: PPO with Multi-Layer Perceptron policy\n",
            "- **💰 Action Space**: Hybrid continuous/discrete (Action Type + Position Sizing)\n",
            "- **📊 Observation Space**: 60-day lookback window with technical indicators\n",
            "- **🏆 Training**: 500,000 timesteps across 5 major stocks\n",
            "- **⚡ Performance**: Up to 7,243% returns with risk management\n",
            "\n",
            "## 🚀 Quick Start\n",
            "\n",
            "### Installation\n",
            "\n",
            "```bash\n",
            "pip install stable-baselines3 yfinance pandas numpy scikit-learn\n",
            "```\n",
            "### For data preparation, you can use Enhanced Enviroment and Stock data processor automated classes for data and enviroment preparation in python files provided in directory\n",
            "### Load and Use the Model\n",
            "\n",
            "```python\n",
            "from stable_baselines3 import PPO\n",
            "import pickle\n",
            "import numpy as np\n",
            "\n",
            "# Load the trained model\n",
            "model = PPO.load(\"best_model.zip\")\n",
            "\n",
            "# Load the data scaler\n",
            "with open(\"scaler.pkl\", \"rb\") as f:\n",
            "    scaler = pickle.load(f)\n",
            "\n",
            "# Example prediction\n",
            "obs = your_observation_data  # Shape: (n_features,)\n",
            "action, _states = model.predict(obs, deterministic=True)\n",
            "\n",
            "# Interpret action\n",
            "action_type = int(action[0])  # 0: Hold, 1: Buy, 2: Sell\n",
            "position_size = action[1]     # 0-1: Fraction of available capital\n",
            "```\n",
            "\n",
            "## 📊 Performance Metrics\n",
            "\n",
            "### 📈 Evaluation Results\n",
            "\n",
            "| Stock | Total Return | Sharpe Ratio | Max Drawdown | Win Rate | Status |\n",
            "|-------|-------------|-------------|-------------|----------|--------|\n",
            "| **MSFT** | **7,243.44%** | 0.56 | 164.60% | **52.11%** | 🏆 Best Overall |\n",
            "| **AMZN** | **162.87%** | **0.74** | 187.11% | 6.72% | 🏆 Best Risk-Adj. |\n",
            "| **TSLA** | 109.91% | -0.22 | **145.29%** | 44.76% | ⚡ Volatile |\n",
            "| **AAPL** | -74.02% | 0.65 | 157.07% | 7.01% | ⚠️ Underperform |\n",
            "| **GOOGL** | 0.00% | 0.00 | 0.00% | 0.00% | 🔄 No Activity |\n",
            "\n",
            "### 🎯 Key Performance Indicators\n",
            "\n",
            "- **📊 Maximum Return**: 7,243.44% (MSFT)\n",
            "- **⚖️ Best Risk-Adjusted Return**: 0.74 Sharpe Ratio (AMZN)\n",
            "- **🎯 Highest Win Rate**: 52.11% (MSFT)\n",
            "- **📉 Lowest Drawdown**: 145.29% (TSLA)\n",
            "- **💼 Portfolio Coverage**: 5 major stocks\n",
            "\n",
            "## 🛠️ Technical Details\n",
            "\n",
            "### 🔧 Model Architecture\n",
            "\n",
            "```yaml\n",
            "Algorithm: PPO (Proximal Policy Optimization)\n",
            "Policy Network: Multi-Layer Perceptron\n",
            "Action Space: \n",
            "  - Action Type: Discrete(3) [Hold, Buy, Sell]\n",
            "  - Position Size: Continuous[0,1]\n",
            "Observation Space: Technical indicators + Portfolio state\n",
            "Training Steps: 500,000\n",
            "Batch Size: 64\n",
            "Learning Rate: 0.0003\n",
            "```\n",
            "\n",
            "### 📊 Data Configuration\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"tickers\": [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"],\n",
            "  \"period\": \"5y\",\n",
            "  \"interval\": \"1d\",\n",
            "  \"use_sp500\": false,\n",
            "  \"lookback_window\": 60\n",
            "}\n",
            "```\n",
            "\n",
            "### 🌊 Environment Setup\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"initial_balance\": 10000,\n",
            "  \"transaction_cost\": 0.001,\n",
            "  \"max_position_size\": 1.0,\n",
            "  \"reward_type\": \"return\",\n",
            "  \"risk_adjustment\": true\n",
            "}\n",
            "```\n",
            "\n",
            "### 🎓 Training Configuration\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"algorithm\": \"PPO\",\n",
            "  \"total_timesteps\": 500000,\n",
            "  \"learning_rate\": 0.0003,\n",
            "  \"batch_size\": 64,\n",
            "  \"n_epochs\": 10,\n",
            "  \"gamma\": 0.99,\n",
            "  \"eval_freq\": 1000,\n",
            "  \"n_eval_episodes\": 5,\n",
            "  \"save_freq\": 10000,\n",
            "  \"seed\": 42\n",
            "}\n",
            "```\n",
            "\n",
            "## 📋 State Space & Features\n",
            "\n",
            "### 📊 Technical Indicators\n",
            "\n",
            "The agent observes the following features for each stock:\n",
            "\n",
            "- **📈 Trend Indicators**: SMA (20, 50), EMA (12, 26)\n",
            "- **📊 Momentum**: RSI, MACD, MACD Signal, MACD Histogram\n",
            "- **🎯 Volatility**: Bollinger Bands (Upper, Lower, %B)\n",
            "- **💹 Price/Volume**: Open, High, Low, Close, Volume\n",
            "- **💰 Portfolio State**: Balance, Position, Net Worth, Returns\n",
            "\n",
            "### 🔄 Action Space\n",
            "\n",
            "The agent outputs a 2-dimensional action:\n",
            "1. **Action Type** (Discrete): \n",
            "   - `0`: Hold position\n",
            "   - `1`: Buy signal\n",
            "   - `2`: Sell signal\n",
            "\n",
            "2. **Position Size** (Continuous): \n",
            "   - Range: `[0, 1]`\n",
            "   - Represents fraction of available capital to use\n",
            "\n",
            "## 🎯 Usage Examples\n",
            "\n",
            "### 📈 Basic Trading Loop\n",
            "\n",
            "```python\n",
            "import yfinance as yf\n",
            "import pandas as pd\n",
            "from stable_baselines3 import PPO\n",
            "\n",
            "# Load model and scaler\n",
            "model = PPO.load(\"best_model.zip\")\n",
            "with open(\"scaler.pkl\", \"rb\") as f:\n",
            "    scaler = pickle.load(f)\n",
            "\n",
            "# Get live data\n",
            "ticker = \"AAPL\"\n",
            "data = yf.download(ticker, period=\"3mo\", interval=\"1d\")\n",
            "\n",
            "# Prepare observation (implement your feature engineering)\n",
            "obs = prepare_observation(data, scaler)  # Your preprocessing function\n",
            "\n",
            "# Get trading decision\n",
            "action, _states = model.predict(obs, deterministic=True)\n",
            "action_type = [\"HOLD\", \"BUY\", \"SELL\"][int(action[0])]\n",
            "position_size = action[1]\n",
            "\n",
            "print(f\"Action: {action_type}, Size: {position_size:.2%}\")\n",
            "```\n",
            "\n",
            "### 🔄 Backtesting Framework\n",
            "\n",
            "```python\n",
            "def backtest_strategy(model, data, initial_balance=10000):\n",
            "    \"\"\"\n",
            "    Backtest the trained model on historical data\n",
            "    \"\"\"\n",
            "    balance = initial_balance\n",
            "    position = 0\n",
            "    \n",
            "    for i in range(len(data)):\n",
            "        obs = prepare_observation(data[:i+1])\n",
            "        action, _ = model.predict(obs, deterministic=True)\n",
            "        \n",
            "        # Execute trading logic\n",
            "        action_type = int(action[0])\n",
            "        position_size = action[1]\n",
            "        \n",
            "        if action_type == 1:  # Buy\n",
            "            shares_to_buy = (balance * position_size) // data.iloc[i]['Close']\n",
            "            position += shares_to_buy\n",
            "            balance -= shares_to_buy * data.iloc[i]['Close']\n",
            "        elif action_type == 2:  # Sell\n",
            "            shares_to_sell = position * position_size\n",
            "            position -= shares_to_sell\n",
            "            balance += shares_to_sell * data.iloc[i]['Close']\n",
            "    \n",
            "    return balance + position * data.iloc[-1]['Close']\n",
            "```\n",
            "\n",
            "## 📁 Model Files\n",
            "\n",
            "| File | Description | Size |\n",
            "|------|-------------|------|\n",
            "| `best_model.zip` | 🏆 Best performing model checkpoint | ~2.5MB |\n",
            "| `final_model.zip` | 🎯 Final trained model | ~2.5MB |\n",
            "| `scaler.pkl` | 🔧 Data preprocessing scaler | ~50KB |\n",
            "| `config.json` | ⚙️ Complete training configuration | ~5KB |\n",
            "| `evaluation_results.json` | 📊 Detailed evaluation metrics | ~10KB |\n",
            "| `training_summary.json` | 📈 Training statistics | ~8KB |\n",
            "\n",
            "## 🎓 Training Details\n",
            "\n",
            "### 🔄 Training Process\n",
            "\n",
            "- **🎯 Evaluation Frequency**: Every 1,000 steps\n",
            "- **💾 Checkpoint Saving**: Every 10,000 steps\n",
            "- **🎲 Random Seed**: 42 (reproducible results)\n",
            "- **⏱️ Training Time**: ~6 hours on modern GPU\n",
            "- **📊 Convergence**: Achieved after ~400,000 steps\n",
            "\n",
            "### 📈 Performance During Training\n",
            "\n",
            "The model showed consistent improvement during training:\n",
            "- **Early Stage** (0-100k steps): Learning basic market patterns\n",
            "- **Mid Stage** (100k-300k steps): Developing risk management\n",
            "- **Late Stage** (300k-500k steps): Fine-tuning position sizing\n",
            "\n",
            "## ⚠️ Important Disclaimers\n",
            "\n",
            "> **🚨 Risk Warning**: This model is for educational and research purposes only. Past performance does not guarantee future results. Cryptocurrency and stock trading involves substantial risk of loss.\n",
            "\n",
            "> **📊 Data Limitations**: The model was trained on historical data from 2019-2024. Market conditions may change, affecting model performance.\n",
            "\n",
            "> **🔧 Technical Limitations**: The model requires proper preprocessing and feature engineering to work effectively in live trading environments.\n",
            "\n",
            "## 🚀 Advanced Usage\n",
            "\n",
            "### 🎯 Custom Environment Integration\n",
            "\n",
            "```python\n",
            "# Create custom trading environment\n",
            "from stable_baselines3.common.env_checker import check_env\n",
            "from your_trading_env import StockTradingEnv\n",
            "\n",
            "env = StockTradingEnv(\n",
            "    tickers=[\"AAPL\", \"MSFT\", \"GOOGL\"],\n",
            "    initial_balance=10000,\n",
            "    transaction_cost=0.001\n",
            ")\n",
            "\n",
            "# Verify environment\n",
            "check_env(env)\n",
            "\n",
            "# Load and test model\n",
            "model = PPO.load(\"best_model.zip\")\n",
            "obs = env.reset()\n",
            "action, _states = model.predict(obs)\n",
            "```\n",
            "\n",
            "### 📊 Real-time Trading Integration\n",
            "\n",
            "```python\n",
            "import asyncio\n",
            "import websocket\n",
            "\n",
            "async def live_trading_loop():\n",
            "    \"\"\"\n",
            "    Example live trading implementation\n",
            "    \"\"\"\n",
            "    while True:\n",
            "        # Get real-time market data\n",
            "        market_data = await get_market_data()\n",
            "        \n",
            "        # Prepare observation\n",
            "        obs = prepare_observation(market_data)\n",
            "        \n",
            "        # Get model prediction\n",
            "        action, _ = model.predict(obs)\n",
            "        \n",
            "        # Execute trade (implement your broker API)\n",
            "        if int(action[0]) != 0:  # Not hold\n",
            "            await execute_trade(action)\n",
            "        \n",
            "        await asyncio.sleep(60)  # Wait 1 minute\n",
            "```\n",
            "\n",
            "## 🤝 Contributing\n",
            "\n",
            "We welcome contributions! Please feel free to:\n",
            "\n",
            "- 🐛 Report bugs and issues\n",
            "- 💡 Suggest new features\n",
            "- 📝 Improve documentation\n",
            "- 🔧 Submit pull requests\n",
            "\n",
            "## 📄 License\n",
            "\n",
            "This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.\n",
            "\n",
            "## 🔗 Links & Resources\n",
            "\n",
            "- **📊 Hugging Face Model**: [Adilbai/stock-trading-rl-20250704-171446](https://huggingface.co/Adilbai/stock-trading-rl-20250704-171446)\n",
            "- **📚 Stable-Baselines3**: [Documentation](https://stable-baselines3.readthedocs.io/)\n",
            "- **💹 Yahoo Finance**: [API Documentation](https://github.com/ranaroussi/yfinance)\n",
            "- **🎓 PPO Paper**: [Proximal Policy Optimization](https://arxiv.org/abs/1707.06347)\n",
            "\n",
            "## 📊 Citation\n",
            "\n",
            "If you use this model in your research, please cite:\n",
            "\n",
            "```bibtex\n",
            "@misc{stock-trading-rl-2025,\n",
            "  title={Stock Trading RL Agent using PPO},\n",
            "  author={Adilbai},\n",
            "  year={2025},\n",
            "  url={https://huggingface.co/Adilbai/stock-trading-rl-20250704-171446}\n",
            "}\n",
            "```\n",
            "\n",
            "---\n",
            "\n",
            "<div align=\"center\">\n",
            "\n",
            "**🚀 Ready to revolutionize your trading strategy?**\n",
            "\n",
            "[Get Started](#quick-start) • [View Performance](#performance-metrics) • [Technical Details](#technical-details)\n",
            "</div>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5150e606",
        "outputId": "66e5bad6-eee6-4db0-bf8a-406b295ce8e3"
      },
      "source": [
        "import os\n",
        "os.chdir('repo')\n",
        "print(os.listdir('.'))"
      ],
      "id": "5150e606",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['eval_MSFT.monitor.csv', 'scaler.pkl', '.gitattributes', 'eval_TSLA.monitor.csv', 'train_TSLA.monitor.csv', 'eval_AAPL.monitor.csv', 'AAPL_performance.png', 'enviromentcreator.py', 'resumer_MyTestExp_20250704_171133.log', 'train_GOOGL.monitor.csv', 'trainer_MyTestExp_20250704_165810.log', 'trainer_MyTestExp_20250704_171341.log', 'train_MSFT.monitor.csv', 'GOOGL_performance.png', 'resumer_MyTestExp_20250704_170925.log', 'trainer_MyTestExp_model_info.json', 'resumer_MyTestExp_20250704_171431.log', 'trainer_MyTestExp_20250704_171133.log', 'README.md', 'config.json', 'processed_data.pkl', '.git', 'resumer_MyTestExp_20250704_171341.log', 'tensorboard', 'train_AMZN.monitor.csv', 'trainer_MyTestExp_data_info.json', 'eval_AMZN.monitor.csv', 'MSFT_performance.png', 'eval_GOOGL.monitor.csv', 'evaluation_results.json', 'trainer_MyTestExp_20250704_170925.log', 'train_AAPL.monitor.csv', 'trainer_MyTestExp_20250704_171431.log', 'trainer_MyTestExp_20250704_164102.log', 'dataprocessor.py', 'final_model.zip', 'AMZN_performance.png', 'TSLA_performance.png', 'trainer_MyTestExp_20250704_164203.log']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c76c2d99"
      },
      "source": [
        "This will change your current working directory to `repo` and list its contents. Look for a main script (e.g., `main.py`, `train.py`, or `run.py`) or another Jupyter Notebook that might serve as the entry point for the RL agent."
      ],
      "id": "c76c2d99"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}